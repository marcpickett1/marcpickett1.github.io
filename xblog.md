---
layout: default
title: "The X Blog"
---

<!-- To publish: cd ~/, then run ~/int/bin/kids -->
<!-- Then: cd blog -->
<!-- Then: git add --all && git commit -m "Foo." && git push -u origin master -->

<!-- post on medium # Atomic Waves and Platonic Forms -->
<!-- post on medium # Artificial Sweetener, Drugs, and Virtual Reality -->
<!-- post on medium ## Habits and Pain -->
<!-- post on medium ## Hedonism -->
<!-- post on medium # The Peacock's Tail -->
<!-- post on medium # Economics and Ethics -->
<!-- post on medium ## Hill Climbing on the Cingulate Cortex -->
<!-- post on medium ## Some Strategies for Maximizing Reward -->
<!-- post on medium # Walking = Falling + Catching -->
<!-- post on medium # Happiness of Rabbits: A Thought Experiment about Evolution -->
<!-- post on medium # Will: Interaction of Cognitive System and Reward System -->
<!-- post on medium # Taste -->
<!-- post on medium ## Specifying Reward: The Bulldog Hugging Robot -->
<!-- post on medium # Designing your Successor -->
<!-- post on medium # Entropy: A Petri Dish Falling into a Volcano -->
<!-- post on medium ## Nihilism -->
<!-- post on medium # Consciousness and Death (How a person never dies) -->
<!-- post on medium # Free Will -->
<!-- post on medium # Conclusions -->

# Fiction: The Castle
#### 2017/04/05/22:15, Wednesday

In a story called The Library of Babel, Jorge Luis Borges describes an endless library filled with books with seemingly random contents.  I view
this as a thought-experiment in combinatorics: Every 300-page book that has ever been or ever will be written sits on a shelf somewhere in this
library.

When we try to visualize it, the hypothetical size of Borges's library is staggering: The number of rooms it must contain would be larger than
the number represented by 1 followed by 100,000 zeroes.  It would be as if every subatomic particle in the universe had its own universe with as
many particles, and every particle in that universe had *its* own universe, repeating this down 1,000 levels, and at the bottom, each subatomic
particle was a room in this enormous library.

In comparison, my construction is quite easy to imagine.  A castle with maybe a hundred million rooms, though I haven't been able to count, with
an intricate network of hallways connecting them.  The castle is large, but by no means infinite.  It has so many rooms that no one has been
able to catalog all of them, though not for lack of trying.  The rooms vary in size.  Most are the dimensions of a small bedroom, and many are
little bigger than a closet.  I've seen more than a few the size of an auditorium, though these are rather rare.

This castle is built into a mountain.  Most of the rooms are deep in the mountain's interior.  If the mountain were a perfect cone, which it is
not, it would be a mile and a half tall and 3 miles wide.  The rooms and the tunnels and staircases connecting them --which take up more space
than the rooms themselves-- leave little space for the actual rock of the mountain, the majority of which has been mined away over the
centuries.

No one has found two rooms that are exactly alike, though some vary in minor details.  For example, one room might contain 19th century hunting
rifles surrounding a full-size taxidermied African elephant.  An adjacent room might be otherwise identical except the stuffed elephant is
Indian.  But in general, the rooms vary significantly.  One enormous room larger than an airplane hangar contains a full scale replica of a
Saturn V rocket amid space suits and operational Mars rovers.  Another closet-sized room contains nothing other than a single monarch butterfly
and a wall calendar.  Some rooms are pristine and a pleasant temperature, others are filthy with polluted air and well below freezing.

There are two aspects every room has in common.  First, there is a plaque above the door entering every room that has a seemingly random string
of 20 letters.  This label seems to be the room's identifier in some bizarre index.  Second, somewhere in every room there is a wall calendar.

Finally, the tunnels connecting the rooms are each lined with moving walkways such that a person may step out of one of the exits from one room
and rapidly be whisked along over a mile of conduits to the entrance of another room.

The connections between the rooms don't follow a simple pattern, but they are far from arbitrary.  One can usually find a theme that any two
connected rooms share.  The small room with the monarch butterfly connects to rooms with other species of butterflies, and a larger room with a
wide variety of insects, and several others.

This castle has a team of "caretakers" who, as a group, zip from room-to-room with the task of dusting the room, taking inventory, and,
importantly, flipping the calendars on the wall to the current month.  The team of caretakers is neither random nor systematic in the order in
which they visit the rooms.  The team of caretakers has existed for millennia, with new members apprenticing and eventually replacing the old.
In a day, the team may visit several hundred rooms.  Despite this, there are rooms that have not been visited for over a thousand years, and
which are buried in layers of dust.  (What process generates this dust is another mystery.)

The caretakers' task is to prevent dust from building too much, and some rooms accumulate dust faster than others, which the caretakers have
picked up on, and have duly modified their routes in accordance.

The more rooms the caretakers try to maintain, the dustier those rooms become.  For several thousand years, the caretakers kept a nearly even
visitation schedule, which resulted in the rooms being uniformly covered in a relatively thin layer of dust.

Better that some rooms are dust free and some very dusty, rather than every room having some dust.  With this in mind, there were periods when
the caretakers agreed to cordon off a small fraction of the castle, only about 10,000 rooms, less than a percent of a percent of the total, to
be visited on a regular schedule.  These rooms were each visited several times a year for a few decades.  But this came at the expense of the
other rooms being completely neglected: time kept marching, and the dust kept piling up ever higher.

Some speculate that the number of rooms in the castle has grown over the centuries, and that the existing rooms become rearranged from
time-to-time.  This is possible.  The walkways are shut down every day after the caretakers have returned to their quarters for the evening.
The caretakers are unable to venture far with the walkways out, so no one has been able to disprove that another crew or some other agent
meddles with the rooms[1].

Some speculate further that the castle started much smaller, with only a few thousand rooms.  If so, then a hundred years was enough time to
clean each room many times.  A caretaker could conceivably visit every room within their lifetime.  Now, a century goes by and only a fraction
of the rooms get cleaned.  Though the caretakers tend to be long-lived, it's inconceivable that a caretaker living today could visit any more
than a tenth of the total rooms.

The purpose of the calendars is to help keep records of when the room was last visited.  Another speculation is that rooms that have not been
visited for a long time --a thousand years or so-- become so filled with dust that the mysterious night crew completely repurposes them,
sometimes closing off all tunnels into the neglected room.  The caretakers, aware of this possibility ever scramble to preserve what rooms they
can.

***

And so it is with my memories of Brussels, which remains frozen as it was over a decade ago, and my cousin who remains 5 years old, though she
is no younger than myself.

They say that until the Renaissance, the collective scholarly knowledge of mankind was small enough that a single person could absorb it all.
Was there ever such a point with mankind's collective tacit knowledge?  Probably not.  Consider all the native detailed knowledge of flora and
fauna in different regions.  If there were such a point, then a person wouldn't benefit much from being born much earlier because he'd already
be on the cusp of human knowledge.

A person could learn almost every field, but it might take him 100 years, at which point, the earlier fields would have advanced.  Some of the
fundamentals would probably be the same, though.  He would also probably forget a great deal, and, the way the human brain is constructed, would
probably be overly influenced by his current context.

Possibly, after a point, since a person has limited memory, a person would simply be in a steady-state in a sense.  That is, he wouldn't
remember his entire life, rather he'd keep living the same period over and over again because he couldn't remember anything else[2].  Perhaps
Chimpanzees (or dogs) are like this too.  After a certain point, they simply relive the same days over and over again, they get in a rut and
become a (many-state) automaton.

![]({{site.url}}/assets/coronaRadiata.gif "The Castle"){:width="600"}

[1] It's unlikely that there is another crew of caretakers during the day.  Though the likelihood of two crews running into each other on any
given day is similar to that for winning a low-stakes lottery, after several centuries, the probability that they *won't* run into each other
becomes almost impossible.

[2] Bill Holstein once said that he can't remember anything new because, to do so, he'd have to forget something he already knew, and, at his
age (through a Darwinian process), almost everything he knew was really important.

# Essay: Immortal
#### 2017/04/06/22:17, Thursday

There is no such thing as a brain transplant.  By this, I don't mean that the technology doesn't exist to transplant a person's brain to another
person, though I don't think our technology is at that point yet.  What I mean is that if I somehow transplanted my brain to another body, this
procedure wouldn't be a brain transplant.  It would be a *body* transplant.  After the operation, I would wake up in a new body, and presumably
have to learn to use new eyes, arms, and other sensors and activators.  In this sense, my body is part of my identity no more than my car is.
Both are familiar machines that I've grown accustomed to, but my brain is what is really *me*.  (Of course, one could apply similar reasoning to
conclude that, since I'm still *me* if you remove any single cell of my brain (and no others) that none of my brain is actually me either.)

Let's assume that our minds are physical just like everything else in the universe.  To assume otherwise would mean we'd have to address the
interaction between the physical and the non-physical, since brain damage and drugs show that physical processes can affect our minds.

That said, we are not our physical neurons, but the *patterns* that they encode.  Douglas Hofstadter and Daniel Dennett describe a
thought-experiment in which you replace your brain cells, one at a time, with functionally-equivalent silicon circuits.  In this case,
"functionally-equivalent" means that the external physical behavior of your silicon brain is identical to that of your biological brain.  So,
without looking inside your skull, I wouldn't be able to tell the version of you that had a silicon brain from the version of you with a
biological brain.  I might also ascribe consciousness to the silicon version of you for the same reason that I ascribe consciousness to the
biological version of you, which is that *I* am the only thing in the universe that I truly know to be consciousness --I just extend this trait
to others because it's more parsimonious to do so.  We might also make an argument that from *your* perspective the silicon brain is still you.
If we assume that, after a few days, we re-replace the silicon circuits back with your original neurons, each modified to account for the
changes in the silicon circuits over that time (i.e., what they've learned), then we'll get back to your brain, which (by the assumptions of the
thought experiment) will be physically identical to your brain as if we had never done the silicon replacement at all.  Your memories of the
experiences of past few days living as the "silicon brain" would be identical to your memories had your biological brain experienced them.  At
any rate, from an outside perspective at least, what makes you *you* isn't your physical neurons, but the *patterns* and information that those
neurons encode.  The substrate --biological neuron or silicon circuit-- doesn't matter.

Like virtually all concepts, the concept of "self" is merely an abstraction we throw on top of the atoms, quarks, or strings of reality so that
we can talk about macro-scale phenomena, where macro-scale here means anything more than a handful of quarks, which is virtually everything in
our day-to-day existence.  And like all abstractions, we can find places where the abstraction of "self" breaks down.  For example, suppose we
perform the silicon-replacement thought experiment as above, replacing one neuron at a time with functionally-equivalent silicon, but after
removing your biological neurons, we reassemble them into your brain in a copy of your body.  Now, there are two *you*s.  You might say that the
"neural" you is the real you, but what if we used neurons instead of silicon in creating the brain of your first body?  Then each copy would
have equal claim of being the true self.  At least, both copies would *feel* and believe the same about being the original you.  A full
discussion of what constitutes one's self warrants another essay!

Suppose you wanted to live forever.  Modern and future medicine might be able to replace your hips or even your liver, but all body parts wear
out, including neurons.  If I wanted to live forever, not only would I have to occasionally "replace" parts of my body, but I'd have to replace
the neurons in my brain.  One way to do this would be to clone myself, as in Robert Heinlein's "Time Enough for Love", then "upload" my
thoughts, memories, etc. to my clone's brain.  Theoretically, the cloned-me could be behaviorally identical to the old me, with the exception
that its joints wouldn't be as arthritic, and it'd be all around in better shape.

If "you" are the patterns encoded in your brain, living forever would mean ensuring that these patterns continue.  So what are these patterns
that make you *you*?  These patterns include things like your beliefs, memories, habits of mind, values, and desires.  They also include your
worldview and your ontology for how you characterize the world.  For example, like many Americans, I associate dogs and cats together more than
I associate either with pigs.  In my mind, dogs and cats are pets, and pigs produce meat.  This isn't true for all cultures, some of which don't
eat pigs, and some eat dogs.  Some of my associations have a more personal bias.  For example, I have a stronger association between cats and
mosquitoes than I assume most other people do, because I have fairly strong allergies to cats, and both cats and mosquitoes have made otherwise
pleasant occasions less so for me.

Where do these patterns come from?  These patterns have only two possible sources: genes and environment.  Psychologists debate the general
contribution of each of these.  We might gain some perspective of the possible influence of genes by noting that our brains have on the order of
10,000,000,000,000 synapses, while the part of our genome that encodes our brain can be compressed to about 200,000,000 bits.  This gives about
50,000 synapses for every bit of our brain's blueprints.  So, only so much can be encoded in our genes.  What about explicit instruction (e.g.,
lectures and what we read)?  If we hear 100 words per minute for 12 hours every day for 40 years, and we assume about 10 bits per word, this
gives roughly 10,000,000,000 bits for natural language input, or about 1,000 synapses for every bit of natural language.  This is 50 times more
than what our genes account for.  As to the question of what informs our synapses, there are still many unaccounted for bits.  I suspect that
genes and natural language are only the tip of the iceberg, and the iceberg's underbelly is tacit knowledge learned through observations and
interactions with others and with the world around us.

One way to live forever would be to upload your consciousness to silicon.  But if that preserves "you", then wouldn't it also preserve you if
you could regenerate a new biological brain and upload your thoughts and beliefs to it?  My claim is that the process of having kids and raising
them is doing something close to this.  But kids are hardly clones of their parents.  There are more than a few examples of staunch Republicans
raising children who go to college and become radical leftists.  I claim that the belief systems that make us *us* get stuck in ruts, and that
kids are a way of resetting this.  I further claim that most of our belief systems are deep and tacit, and that more measurable beliefs, such as
political leanings, are relatively superficial.  Therefore, kids allow us to retrain our belief systems.  By interacting with your kids, they
copy the important parts of your beliefs and habits.

What do I mean that belief systems get caught in ruts?  One example is my addiction to Emacs.  During college, I learned to use the Emacs
word-processor, and over the past 20 years, I've gotten to the point where it's difficult for me to write prose or programs using any other
word-processor.  This was fine in the late 1990s, but Emacs is starting to become dated.  Emacs uses a large number of arcane key-combinations,
and these have become entrenched in my muscle memory.  For example, pressing the "control" key at the same time as the "k" key deletes the text
from the cursor to the end of the line the cursor's on.  When I habitually type this while composing an email in Gmail, it tries to create a
link.  Maybe I ought not to upload the Emacs key-combination habits to my clone.  My speaking accent has also crystallized into American
English, and if I were to move to another country, I would always mark myself as American every time I spoke.  Maybe it'd make sense to let the
new me speak without an accent.

I also have many outdated beliefs.  These are tacit, not explicit, so it's not as simple as correcting a misunderstood fact.  For example, I was
raised Catholic, but I am now Atheist.  To this day, 25 years after my conversion, I'm still digging up beliefs that are rooted in Catholicism.
For example, Catholicism believes in an afterlife and divine justice.  One consequence of this is that a follower need not worry much about
righting things while alive because God will judge all things.  Another consequence of Catholicism's belief in an eternal afterlife is that our
time on Earth is mostly preparation for the afterlife, which at infinity years vs. 80 odd years is what our existence is really about.

Many of my tacit beliefs and patterns need updating, but they're so interconnected that it's difficult to change just one thing.  In Korea,
there is a system of heating called "ondol" which means warm stone.  Korea gets quite cold in the winter, and apartments are frequently heated
through floor heating.  One consequence of this is that many people spend a lot of time on the floor of their homes.  People sleep on the floor
and regularly sit on the floor during meals.  No one wants to sit on a dirty floor, so it's custom to remove one's shoes immediately when
entering a home.  A consequence of *this* is that Korean shoes tend to be easy to slip on and off.  Also Korea doesn't have as much need for
home furniture like beds and kitchen chairs.  The point is that one pattern of behavior can become entrenched with others so that changing a
simple thing, like wearing Doctor Martin boots (which take a long time to lace up) would put pressure to change many other behaviors.

These sorts of behaviors exist on a family-sized scale as well.  It wasn't until I was in my late teens before I realized that my own family has
a custom not shared by everyone.  It's about dealing with trash in the car.  My parents never explicitly told me all the rules of the custom,
but this is how they (and now I) deal with trash while driving: keep a durable plastic bag of a particular shape and size hooked on the gear
shift and hanging to the passenger side.  These bags might be the sturdy bags you might get at a gift shop.  When you stop for gas, empty the
bag into the gas station trash, but keep the bag.  Why keep it?  Because they're hard to come by.  Why not just use a regular grocery plastic
bag?  The shape of the holes on these bags are such that they hang so that it's difficult to put trash into with one hand while driving.  Since
you keep these bags a long time, you don't want to put trash into them that might stink up the car.  For example, you can't just put an apple
core into it.  Instead wrap the apple core in multiple tissues before putting it in the bag.  Again, this is a small coherent system (and also
an example of a tacitly passed habit).

Why is it hard to change beliefs?  When learning, we build things in terms of concepts we already know.  It becomes difficult to change an
underlying concept with so much built on top of it.  I've heard that there exist some nuclear power plants that still have 1950s control
systems, with 1960s controllers on top of those, and even more modern control built on top of those.  The issue is that you can't take the plant
offline to unplug the controller.  You have to start with a clean slate!

We can get another view of why a "reset" might be necessary by considering what it would mean to live for centuries.  For example, consider the
scars a 10,000 year old man might have.  Over the course of several hundred years, one is sure to break some bones and break their skin.  Both
of these would become filled with scars in the same way that the surface of the moon is pocked with scars from eons of asteroid strikes.  These
are only the scars we can see.  Surely, entropy would make its mark on that person's internal organs.

And what about his cognitive state?  Is there some sort of local optimum or cognitive aging analogous to memory leaks in computers, where the
most practical solution is to reboot?  You're a different person than you were 20 years ago.  Imagine if you lived for thousands of years.
Would you reach a fixed-point, or would you continually change depending on your context.  If it's the latter, then like the ship of Theseus,
even the patterns that make you *you* might be replaced such that the set of patterns that comprise you at one time are completely disjoint from
your "pattern set" at some time in the future.  At this point, you might say that *you* are some meta-pattern that holds constant during that
span.

If you lived for thousands of years, would you notice patterns that can't be seen otherwise, or is cultural transmission powerful enough to find
these patterns?  For example, written and oral history allows historians to find trends in empires that span centuries.  On the other hand,
firsthand experience is often difficult to replace, and no one had firsthand knowledge of the entire Roman Empire.  Even if a person could live
long enough, he couldn't be present at all events, as important events often took place simultaneously hundreds of miles apart.

Main points:
- We are patterns.
- We can upload these patterns to other systems, including computers and other people.
- People can acquire mental cruft, so "rebooting" has an upside.
- Our kids capture the fundamentals of our patterns, not the specifics.
- The bulk of our patterns are tacit, and are learned through years of observations and interactions, as opposed to explicitly taught knowledge.

Conclusions:

1. In a sense, an adult is a being thousands of years old, or has nearly the same Weltanschauung as if he lived for thousands of years.
Conversely, figures from antiquity, such as Marcus Aurelius are still living, though distributed among millions of cognitive descendants.

2. You can upload your thoughts to other people, your kids just naturally learn from you, so are a first candidate.  Isaac Newton died
childless, yet his ideas live on.

***

#### Addendum 2017/05/12/20:19

I got a new computer today and spent more time than I should have transferring my files from one computer to the other.  The hardware wasn't
exactly the same, so a rote copy wouldn't work.  I had to monitor the files a little.  I was surprised at how much "cruft" had built up in my
old computer.  I didn't copy most of this to the new computer.

# Some Artwork
#### 2019/01/27/09:46, Sunday

A composite Night/Day picture of Toronto.

![]({{site.url}}/assets/toronto.jpg "A composite Night/Day picture of Toronto."){:width="600"}

***

Here's a popup pyramid I made some years ago.

![]({{site.url}}/assets/marcitlan.jpg "A popout pyramid."){:width="600"}
![]({{site.url}}/assets/marcitlanpens.jpg "The making of."){:width="600"}

***

Escher with Penrose tiling.

![]({{site.url}}/assets/penescher.jpg "A mixture of Penrose and Escher."){:width="600"}

# Essay: Time, Money, Love, Life, and Cycles
#### 2020/08/18/09:44, Tuesday

This is an exploration of the connection between Life, Time, Love, and Money.  Some of my basic assumptions about these topics, especially
money, have shifted in the past several years, and I am reexamining these topics for the first time in several decades.

I was brought up with the attitude best summarized by the biblical phrase that "the love of money is the root of all evil".  The pursuit of
money was considered greedy and even discussing personal wealth was distasteful.  During graduate school, I lived comfortably on a $24,000
annual stipend, and wondered what people who made 5 to 10 times that amount did with all their money.  Time, not money, was the main thing
preventing me from accomplishing my goals, I claimed.  I now earn considerably more now, and I've had a few key realizations about money that
has challenged my earlier attitudes:

* The first is along the lines of thought given by [Ayn Rand](https://atlassociety.org/commentary/commentary-blog/3988-the-morality-of-money) or
  [Paul Graham](http://www.paulgraham.com/gap.html): that money *can* be a result of value that one adds to society.  It's not a zero-sum game,
  where to make money, someone else needs to lose that same amount.
* The second realization is that the adage that "time is money" can also work the other way around: "money is time".  That is, the normal
  meaning is that time spent horsing around is time that could be spent making money.  But the reverse can also be true, where money can be used
  to help free up time.  For example, one can order groceries to be delivered instead of spending an hour at the grocery store.  Assuming the
  delivery-person also makes a dozen other deliveries in your area, this is perhaps 3 hours of his or her time, but saving 12 hours of people's
  time altogether (in addition the gas needed for 11 trips to the market).  Not only can one save time by paying other people to (more
  efficiently) do tasks, but one can save time by buying tools.  A riding lawnmower being a simple example.
* Finally, I remember feeling sorry for CEOs or other high-income earners, each spending his or her precious one-and-only life in the pursuit of
  money.  "Who wants to look back on their life as an old man and remember only hours of grind?  All for a fortune you can't take with you?" I
  asked.  The key realization that dispelled this attitude was that work itself can be rewarding.  I have hours playing the video game
  [Civilization II](https://en.wikipedia.org/wiki/Civilization_II), managing the growth of my virtual empire, attending to each of my digital
  cities, and optimizing.  I've since learned that one's work can be even more rewarding: One's work can easily have deeper complexity than a
  video game, you are often working in the camaraderie of a team who also care deeply about the project (as opposed to the isolation in which I
  often played Civilization), and the "empire" you build actually helps people, thereby making the world a better place.  And it is because of
  this point that you get paid.

### Life is Cycles, Cycles can Affect Our Environment, Cycles are Limited, Love grounds out in Cycles

A person born today in America has a life expectancy of 78.9 years, or roughly 700,000 hours.  A person's life is what happens during those
700,000 hours.  But not all those hours are equal.  In terms of capabilities, an hour when you're sick or underslept isn't the same as an hour
when you're well and refreshed.  So it might be more accurate to say that one's life is a sum of their *cycles*.  This is a term borrowed from
Computer Science.  Originally, this meant CPU clock cycles, and was the basic unit of computation.  An instruction might take so many cycles.
In [hacker jargon](https://www.eps.mcgill.ca/jargon/jargon.html#cycle), this became a metaphor for a person's thinking and, more generally, to
one's *productive* time.  For example, a teammate of mine might say "I can't commit to that project yet because I won't have the cycles for it
until the summer."  Of the 700,000 hours, somewhere between a quarter and a third will be spent sleeping, so, in very round numbers, an average
American's life consists of 500,000 productive hours.  If a person dies at a young age, they have no more productive cycles.  The person --the
process that *is* the person-- stops.  That person will never write another email, listen to another symphony, or pay another phone bill.  The
same is true for a person who is in a car accident and is in a coma on life support for 30 years before the plug is pulled.  Death means the end
of cycles.  Whatever the number is, *the supply of cycles a person has is limited*.

Now, what do we do with our cycles?  A person can use their cycles to affect their world.  He or she can take actions to cause a house to be
built.  A person can also spend cycles to cause internal changes, such as by reading, thinking, or meditating.  In any case, being is doing.  At
any moment you're alive and awake, you're causing change either internally or externally.  Even if you're watching mindless TV, you're making
changes.  Unless you're an amnesiac, a day after you've watched a show, you can tell me what the show was about, which is something you couldn't
have done before watching the show.  Some people (myself included) enjoy sitting on the beach watching waves.  I don't know what internal
changes this makes, but presumably it's doing something, because eventually I'll have my fill of wave watching, and I'll want to do something
else.  If there were no internal changes, then I'd never become "full".

Ideally, we would use our cycles to mold our world in a direction that suits us.  If I'm hungry, I can use cycles to eat.  I can also use cycles
to feed my kids.  The question of which direction to mold the world is non-trivial.  I might have contradictory goals, such as wanting to eat a
pint of ice-cream and also wanting to lose weight.  What direction we actually want to push the world aren't necessarily conscious goals, any
more than a rabbit consciously understands why he mounts other rabbits.  What these goals are is outside the scope of this essay, but I suspect
they ultimately ground out in "Do things that will pass on genes that are like yours.".

Cycles are the things that make up life, they're finite, and we can use them to cause changes in the world, to mold the world to our liking.  A
person's life is the sum of their actions, where I'm defining "action" broadly enough that things like thinking and watching TV are also
"actions".  These actions cause changes in their world, and, ideally, would change the world in some way that's desirable for them.

So what is life, and how can we make the most of our life?  Benjamin Franklin (1706-1790) might say that life is time.  He wrote "Dost thou love
life? Then do not squander time, for that is the stuff life is made of.".  That is, a human lifetime is made of the moments that comprise it.
But I'm coming to the conclusion that life, however much time we have, isn't about time exactly, but *action*.  By this, I mean how we can
causally affect the world (or ourselves).  In this sense, in addition to physical actions like harvesting wheat, building a table, or digging a
ditch, action also includes seemingly sedentary activities like reading, thinking, writing, and talking.  The effect of some actions is greater
than others.  For example, playing video games probably doesn't cause as big a ripple as publishing a paper.

A person's life is the sum of their actions.  During life, we have a finite amount of actions we can take.  Death is an end of our actions.  If
someone is killed or dies early, it means that they can no longer affect the world through their actions.  All of these effects are behind them,
and there will never be any more.

Life is our ability to causally affect things in this world.  After we die, we are no longer able to directly affect things.  The amount of
action we have is finite.  We can apply actions to our own goals or for the goals of others.  We can increase our actions by finding and using
force multipliers.  This includes both getting other people to help us with their actions (and sometimes the goals are aligned), but it also
includes using machines as a lever.

This is one way to think about money.  For a long time, I thought of money as a certificate for goods.  I give you a dollar and you give me a
doughnut (or whatever).  I later watched a documentary called The Crash Course, which amended this view to be that money is "a contract on human
labor".  For example, you're not really paying for the doughnut, you're paying for all the labor that went into harvesting the wheat, cutting
the sugarcane, baking the doughnut, delivery, etc. that caused the doughnut to come into existence (and in my hand).  This also makes more sense
when you consider paying someone to change the oil in your car or review a legal contract.

But the idea of life as a finite set of actions modifies this slightly to money being a contract on action.  And not necessarily *human*
actions, if someone figures out a way to automate actions, then money can pay for those actions (though presumably at a much cheaper rate
abiding by laws of supply and demand).  If money is a contract on action, and action is the stuff that life is made of, does more money mean
more life?  Can money be thought of as a force-multiplier?  Maybe..  One issue is that, if we assume that someone's incentive to do what we ask
is getting paid, then we need to be careful about what criteria we use to evaluate whether they've done their job.  As a trivial example,
suppose we ask someone to make paperclips for us.  If we pay them solely by the number of paperclips they produce, and their only motivation is
getting paid, they're eventually going to figure out that the same amount of their action can produce more low-quality paperclips than high
quality ones.  So, you need to frame the incentive to take quality into account, but any system you come up with will probably have some way to
game it, unless you're careful.  It's a little like the story of The Monkey's Paw, where a magical monkey paw grants wishes, but abiding by the
literal meaning of what you ask it.  You might ask the paw for a million dollars, but it might grant it by causing a loved one to die so you can
cash out on the insurance policy.

This is where "love" comes in.  I think love is an overloaded term with nearly disjoint meanings.  The Greeks discussed this over 2,000 years
ago, so I won't delve too deeply there, but the kind of love I mean here might be called "agape" or the kind of love a father has for his
children.  I view this kind of love as grounding out --that is, its actual manifestation in the physical world-- in the dedication of action,
but different from money because you don't have to worry about incentives.  That is, a father will do what he thinks is in his kids best
interest (which might not always agree with what his children believe is in their best interest, and people might not always agree with
themselves what is in their best interest, as I discussed in "The Marshmallow Test and Three Versions of You").  If we view things this way,
then loving someone is literally giving part of your life to them.

Mozart is quoted as saying that love is that heart of genius.  I'm paraphrasing, and who knows if he actually said this, but the point is that
love, as in "dedication of action", is what makes great works.  If you spend time in the shower thinking about your project, chances are it'll
be better than one you aren't as passionate about.

### Money is Cycles too

Money is a contract on (others') cycles.  Ideally, a trade of cycles would be "fair".  This is a basic principle of economics, that I can
exchange some of my cycles for some of your cycles.  If I'm more effective than you at making arrows, and you're better than me at hunting game,
I can trade some of my cycles making arrows for some of your cycles hunting game.  In practice, I give you the product of my arrow-making cycles
(the arrows themselves), and you give me the product of your hunting cycles (the meat).

In practice, income inequality still doesn't make complete sense to me.  In a free market, of course, we'll expect significant inequalities in
wealth distribution.  On the other hand, I've worked both as a laborer making minimum wage and as a researcher at a top tech company making
"doctor money".  Money aside, the tech job is much, much easier.  The labor jobs was humping lumber for carpenters to frame a house.  A typical
day was where I'd wake up at 6:30, drive 45 minutes to be at the construction site by 7:30, spend 10 hours there (which included two 15 minute
breaks and a half-hour lunch), then drive home, eat, sleep for 9 or 10 hours (I was pretty exhausted), then wake up and do it again, five days a
week.  If you're keeping track, I got home around 18:30 and went to bed around 21:00, leaving about 2 and a half hours to eat dinner, shower,
and do other things.  The work was in the hot sun, and included me carrying planks, boards, and other heavy objects to two carpenters who nailed
them in.  I never actually hammered anything in, which would have been a little more interesting.  I just carried wood.  In contrast the tech
job involved me doing interesting work in an air-conditioned office, in a comfortable chair, with unlimited drinks, coffee, and snacks.

The Economic difference is that any able-bodied person can hump lumber, while there's a limited supply of people who know how to do my tech job.
But is it?  Anyone with the right mindset and a high-school diploma could learn to do my job in 6 years.  Give them a full ride to Stanford with
plenty of guidance, and they'll be at least as able as me.  (Though that would take years, and my skills are in demand *now*.)

The inequality becomes even more extreme.  For example, when they were destroyed, the World Trade towers in Manhattan were largely owned by one
person, Larry Silverstein.  These buildings were over 1,000 feet tall, and measured 150 by 150 feet, for a total combined volume of over 5
million cubic yards.  If a single person were to construct and finish a building at the absurdly fast rate of a 50 cubic yard room every week
(including plumbing, drywall, electrical, etc.), this would take 7 million days or 112 million hours, or over 200 lifetimes worth of cycles,

Again, it makes sense economically, but it's still hard to reconcile the reality that one person can effectively leverage the cycles of over 200
other people.

And what is life like for the construction workers building the towers, and risking *their* lives --not Larry Silverstein's-- at high altitude.
I assume that many of them enjoyed their work and may have gone to work on freezing windy days even if they were financially independent.  But I
suspect a larger number merely "put in the hours" and watched the clock, waiting for their shift to be over, so they could go home and do use
their cycles more directly on what they wanted to do.

### Cycles Well Spent

In his essay on the Shortness of Life, Seneca (c. 4 BC â€“ 65 AD) wrote "Life is not short, but we make it so...  The amount of time we really
live is small.  The rest of our days is spent just existing.".  From this, I ask myself "What is time spent living vs. time spent existing?" or
more pointedly, "What is time well spent?"

That is the question: What is time well-spent?  What is living vs. merely existing?  I haven't yet come up with a satisfactory answer.  Though I
have lots of examples of time that's *not* well spent (for me, at least): spending hours online (YouTube in particular), too many video games,
being stuck in traffic.  I think running my workshop was time well spent.  Well spent time also tends to be things outside my comfort zone too.
I don't have a general answer though.  I'd guess that, if money weren't involved, spending time in drudgery falls in this category.  It's just
cycles of your life that you're giving up.

For what it's worth, Seneca gives an answer for what is time well spent.  In short, cycles should be spent *understanding* life and the world:

> "Of all people, they alone who give their time to philosophy are at leisure, they alone really live. For it's not just their own lifetime that
> they watch over carefully, but they annex every age to their own.  All the years that have gone before are added to their own.  Unless we
> prove most ungrateful, those most distinguished founders of hallowed thoughts came into being for us, and for us they prepared a way of
> living.  We are led by the work of others into the presence of the most beautiful treasures, which have been pulled from darkness and brought
> to light. From no age are we debarred, we have access to all, and if we want to transcend the narrow limitations of human weakness by our
> expansiveness of mind, there is a great span of time for us to range over.  We can debate with Socrates, entertain doubt with Carneades, be at
> peace with Epicurus, overcome human nature with the Stoics, and go beyond it with the Cynics. Since nature allows us shared possession of any
> age, why not turn from this short and fleeting passage of time and give ourselves over completely to the past, which is measureless and
> eternal and shared with our betters?"

I can also list things I did ten years ago that I'm glad I did.  Activities like traveling, having new experiences, and *connecting* with
people.  Additionally, there's some work I'm not as glad I did.  This includes most busywork.  But there's also work I'm glad I did.  Writing,
creating things, and developing new algorithms generally fall into the latter category.  The general trend is that staying in my comfort zone
(watching TV, playing video games) is generally not time well-spent, while branching out of it is.  Again, this heuristic tells me what *isn't*
time well-spent, but isn't so good for deciding what *is* time well-spent.  Sitting on a hot stove would definitely be outside my comfort zone,
but not time well-spent.

Paul Graham gives [a heuristic](http://www.paulgraham.com/procrastination.html) for deciding on what is "small stuff" as "work that has zero
chance of being mentioned in your obituary".  This might be too stringent for deciding what is time well-spent.  I consider traveling in Asia
for several weeks to be time well-spent if one has never done it before, but this trip is unlikely to be engraved on my tombstone.

From her work in end-of-life hospice care, Bronnie Ware lists [the top five regrets of the dying](https://bronnieware.com/regrets-of-the-dying/)
as:

1. I wish I'd had the courage to live a life true to myself, not the life others expected of me.
2. I wish I hadn't worked so much.
3. I wish I'd had the courage to express my feelings.
4. I wish I had stayed in touch with my friends.
5. I wish that I had let myself be happier.

Again, the message I take from these is to avoid being caught in ruts, but that's also saying what *not* to do, not what *to* do.  One heuristic
I've found for what to do is to consider what things of value I did 10 or 20 years ago, then extrapolate to today.  If I were forced to describe
what *to* do based on this, I'd say branch out, be creative, learn, go on big new adventures, connect with people, and ultimately create
something of value for people.

Another is by looking to examples of other people.  Richard Branson's autobiographies have been inspiring.  At least it matches my idea of what
makes a full life (and of course, he's the one telling the story): he has had greater impact on the world through his work, adventure, and also
a loving family life.  One could do worse.

### Cycle Leverage

Whether or not we adopt Seneca's definition of living, I see a few ways around the problem of spending precious cycles on drudgery when they
could be spent on "living":

1. One way around the problem of needing to spend cycles on drudgery is to find a way to get paid to do what you would spend your cycles on if
   money weren't a concern.  I consider myself fortunate that my current job is very close to this.  My only issue is that I don't know how long
   the job will last.  The economy could tank or any number of other factors could cause me to lose my job.  I view virtually anyone who has
   been at Google over 10 years and still working there to be in the category of people who are working because that's what they love doing.
   After ten years at Google one generally acquires enough investment savings to retire.  Being a CEO can seem like a stressful job, with
   straining schedules.  But I suspect that most Fortune 500 CEOs could easily retire if they wanted and instead continue working for "love of
   the game".
2. Another way is through leveraging *other people's* cycles.  This is basically what getting rich and living off passive income is doing.  The
   same for running a company with employees.  If you acquire $20 million, then you can reasonably expect to withdraw at least $200,000 every
   year from passive (investment) income for the remainder of your days, even accounting for slow markets, taxes, and inflation.  Depending on
   estate taxes, with prudence this could last through the remainder of your kids' days too.  I've seen estimates for the amount needed to
   achieve "retire and live-off-the-interest" income as low as $650,000, certainly more attainable than $20M.
3. The last way I see is through automation, leveraging cycles of *machines*.

I'll dive more deeply into 2 and 3 in the next two sections.

### Drudgery

The idea of living off of capital raises some issues.  One is the question of how a person acquires the capital in the first place.  How does
one acquire $650,000 to $20M?  Of course, one can gain this money by gambling or speculating, but the most effective way today seems to be
either to start a business or to work in a high salary job (doctor, lawyer, and increasingly tech).

Ideally, if I acquire $10M over a decade working as a lawyer, this means I've added over $10M in value to society.  In terms of cycles, this
means that I've accomplished, in net, what would take over $10M worth of *other people's* cycles to accomplish, compared to if I had just sat
idle during that time.

I still find this hard to grok.  Minimum wage in Bangladesh is just under 25 cents per hour.  (Before adjusting for purchasing power parity,
Bangladeshi minimum wage is just under 10 cents per hour.)  Conceptually, this means that my cycles over the 10 years accomplished more than 100
million hours of Bangladeshi laborers.  Even if I assume I worked long 80 hour weeks with no vacation, this still means I was able to accomplish
more over 10 years than 2,000 Bangladeshi laborers working the same period.  In theory, I can see this working through leverage.  A much
simplified example might be if I were the sole inventor and producer of combine harvesters.  (In reality, the invention and manufacture of these
machines is an entire industry.)  Now, I, as a single person with one combine, can harvest and thresh as much wheat --150 acres-- as previously
required at least 150 serfs.  I can further multiply this effect by building 1,000 combines and employing as many drivers to do the work of
150,000 serfs.  In this much simplified scenario, 150,000 times as much wheat had been harvested as it would have been had I not existed.  In
this last case, is it really true that one person could invent something that 150,000 serfs could not?

I don't know how often the ideal case pans out.  That is, one could arguably find instances where a person *legally* earned a large sum of money
without a proportionally net positive effect on society.  For example, some lawyers and Wall Street investors are sometimes targeted as
examples.  However, I'll assume the market has some degree of efficiency, so with broad strokes, a person's earnings are proportional to their
net contributions.

Another issue with living off of capital is that *someone else* still has to do the drudgery.  Drudgery can range from being unpleasant, such as
hard labor, to boring, such as factory work, to dangerous, such as a worker on an oil rig in Siberia or a front-line trench soldier in the First
World War.  (My grandfather, Michael Samuel Pickett, was shot twice in this last unenviable position.  He survived with a metal plate in his
head.  We still have his helmet with the bullet hole in it.)

This might be what Karl Marx was getting at by questioning why the owners of machines (capital) should reap the benefits, when it's the workers
who are spending *their* cycles to produce goods.  Of course, we now know many of the problems that Marxism produces, including that Marxism
removes much of the incentive for people to create the machines in the first place.

An extreme version of leveraging others' cycles is serfdom or slavery.  Of course, slavery has been outlawed in all recognized countries (though
there remain an estimated 40 million people who are effectively slaves through human trafficking).  Even if we focus on *legally* leveraging
others' cycles, there still exists common situations, "wage slavery", where one is coerced to spend their cycles for someone else, often at high
exchange rates (as in one cycle for one person might be exchanged for ten cycles of another person).  For example, a head-of-household earning
minimum wage in Maryland, $10 per hour, would have to work 100 hours to pay for a modest monthly rent of $1000.  For 40 hour work-weeks, this
would leave less than 80 work hours per month for other necessities, such as child care.  Chances are, the person would need to supplement their
income by working more hours (also at low-skilled jobs).  If they're raising a family, this would leave little extra time for their own
education to move to higher-skilled jobs.  It's not impossible to break out of this cycle, but it's not easy either.  As it is, the person has
little choice about how they might spend their cycles, and their situation is nearly tantamount to slavery or serfdom.

This is at one level in the United States, but it can be more extreme elsewhere in the world.  For example, Bangladeshis in Saudi Arabia are
often paid pennies for an hour of menial labor.

As I see it, the worst part of drudgery isn't that it can be boring, unpleasant, or dangerous, but that drudgery has an *opportunity cost* for
the one doing it.  Cycles that we spend in drudgery are cycles that we aren't spending in other activities.  These are cycles we're not spending
with our loved ones or directly forging the world in the direction of our liking.  This wouldn't matter as much if our cycles were unbounded,
but we only have so many cycles in life, it seems counter to one's interest to spend them advancing someone else's agenda.

### Leveraging Cycles through Automation

It has long been a dream to automate away tedious labor, and especially in Computer Science related fields such as Artificial Intelligence.
There's a saying in Computer Science that goes "Never work yourself if you can get a computer to do the work for you.".  It's not a coincidence
that the term "Robotics" stems from the Czech word "robota" meaning drudgery.  The term originated from a story about the technological creation
of artificial workers.

Automation is a force multiplier.  It can multiply the effects of a person's cycles manyfold.  In the US in the early 1800s it took 56
person-hours to grow and harvest one acre of wheat.  By the 1950s, that number had dropped to 4.6 hours, and by the 1960s, it was down to 2.9
hours, and by the 1990s had decreased to 1.6 for large-scale operation.  Of course, this trend has been due to advances in tractors and other
automation.  In addition, advancements in fertilizer and weed and pest control have nearly tripled the yield per acre between 1950 and 2011.  I
can only assume corresponding advancements in factory automation has drastically decreased the number of (person) cycles needed to manufacture
any given product.

Today, many jobs can be done with only a laptop and an internet connection.  Only around
[13%](https://www.bls.gov/opub/ted/2017/physical-strength-required-for-jobs-in-different-occupations-in-2016.htm) of jobs in America require
"heavy" physical labor, and this percentage [has decreased over
time](https://www.bls.gov/opub/ted/2016/employment-by-industry-1910-and-2015.htm).  In information technology, automation is improving [at an
exponential rate](https://en.wikipedia.org/wiki/Accelerating_change#Kurzweil's_The_Law_of_Accelerating_Returns).  This means the possibility to
leverage one's cycles is increasing at an exponential rate.  I view automation as the ultimate solution to cycle leverage.  Not only is it less
ethically questionable than exploiting other people's cycles, it's ultimately more scalable, following the [Law of Accelerating
Returns](https://www.kurzweilai.net/the-law-of-accelerating-returns).

# Essay: A Life Cut Short
#### 2020/08/19/09:57

Another way to approach the question of what cycles makes cycles well spent is to ask what makes a full life.  What would be a complete life?
Is it sensible to ask what it would mean to fulfill one's destiny?

Long before he wrote The Lord of The Rings, J.R.R. Tolkien fought in the Battle of the Somme during the First World War.  That same battle cut
short the lives of over 300,000 people, most of them young men.  Likewise, Ernest Hemingway, Roald Dahl, Kurt Vonnegut, and many others all
faced firsthand combat before writing any of their great works.  Between the two world wars, roughly 100 million lives were cut short.  How many
of these were potential Hemingways?

So what would be a life *not* cut short?  This might include not only doing the "right" thing during the time we have, but being allotted enough
time.  We accept that 90 healthy years is a fortunate amount.  It's more than most people get.  So, let's suppose we get this..  What would be
the end after 90 years?  Who might be an example?

John Horton Conway passed away recently at the age of 82.  He is most remembered for inventing a cellular automaton called "Life".  It's
noteworthy that this work was popularized in 1970, when Conway was 32.  Had he died before his 33rd birthday, had all his accomplishments after
1970 been "erased", I would speculate that wouldn't change much proportionally regarding his contributions to the popular culture.  I knew
almost nothing about his life outside of Life.  Of course, he didn't just sit on his hands for the next 60 years.  He continued making
accomplishments both professionally and personally, but 90% of his worldwide "impact" had already been accomplished.  Inventing Conway's Life is
a more significant contribution to world culture than most people make, including myself.

Tolkien went on to write The Hobbit (1937, age 45), The Lord of the Rings (last volume published 1955, age 63), then several other works before
his death in 1973 at the age of 81.  These are only the things we read about in Wikipedia pages.  Tolkien was a father to four children.  He
wrote illustrated letters to them, and this is in his Wikipedia page because these letters were published.  It's only a fraction of what goes
into being a loving father.

Can we say Tolkien's "point" was to produce The Lord of The Rings and be a great father to his four children?  Can we say that Conway's "point"
was to give the world his Life automaton?  This might all be resting on a tacit assumption that a life is best when it looks like a classic
story arc from a high-school creative writing class, with a beginning, crisis, rising action, climax, resolution, and finally "The End" with
curtains drawn.

What's an alternate view?  We can view a person's life as an aimless process?  Jupiter's Great Red Spot doesn't have a "goal" as far as I can
tell.  It's the conflux of surrounding processes, like a maelstrom in the ocean.  It just *is*.  But people are willful creatures.  Any decision
a person makes is based on some criteria.  There are grey areas to be sure, but a person can look at two outcomes for their life and have an
opinion about the *value* of them, often preferring one (winning a Nobel prize in Physics) over another (getting Mad Cow disease).

I think the best I can do at this point, is through examples.  You might not agree with his business ethics, but Bill Gates created the
Microsoft empire, then did much to make the world better through his foundation.  Carnegie, Vanderbilt, and Rockefeller among others had similar
stories.  Did each of these suck every ounce from their time on Earth?  Of course not, but you could do worse.

The obvious cases of examples might be the greats: Dali, Newton, Churchill, and so on.  What these all had in common is they had some sort of
worldwide impact.  What about Mozart, who died at age 35, still composing his Requiem?  One can only speculate what symphonies would have been
written had he lived his "three score and ten".  In Mozart's case, had radical life extension been available, would there be any point where we
would say the "Mozart process" had finished its goal?  What about Huschle?  You've probably never heard of Mary Magdalene Huschle (1896-1971)
because she is my grandmother.  She's not famous, but at age 55, she took on the brunt of raising my mother from an infant to an eight-year-old.
She passed away in her mid-70s having lived a "complete" life in my view.

What can we induce from these examples?  One conclusion might be that we *expect* our journey to take 70 to 80 years and plan accordingly.  For
example, Andrew Carnegie did this explicitly in his [dictum](https://en.wikipedia.org/wiki/Andrew_Carnegie#Andrew_Carnegie_Dictum), which stated
that a person should spend the first third of their life on education, the second third acquiring wealth, and the last third on philanthropy.
In his own 83 years, he started philanthropy at age 46.  Presumably, if he had expected to live to be 150, he would have started philanthropy at
age 100.

When Oliver Sacks was in his early 80s, he wrote a collection of reflections on his impending death from cancer.  In my view, he seems to be at
peace that the world is in a good place and that his work is finished here.  He is comfortable with the competence of the next generation of
physicians and ready to pass the torch.

# Essay: Happiness of Rabbits: A Thought Experiment about Evolution
#### 2020/08/20/10:04

TL;DR: We can gain some insights by looking at life from a "designer's" point of view.  The notion of *happiness* and *desires* might be useful
from this point of view.

***

To help us get a handle on what the meaning of life might be, I'll propose an intuition-pump that involves rabbits in Australia.  Rabbits are
not native to Australia, but today there are millions of rabbits there, all descended from a few dozen brought over from Europe.  Suppose we
were able to go back in time before rabbits were introduced to that continent, and suppose we played a game, that I'll call *hare wars* similar
to [core wars](https://wikipedia.com/core_wars), where competing players design artificial rabbits, then we drop a small population of each
player's rabbits in pre-colonial Australia and see which player's rabbit population is higher after a few centuries.  To constrain things, we'll
make it so that the players are given identical rabbit *body* designs, and they're only allowed to design the *brains* of the rabbits.  The
players can make the rabbits' brains as powerful as they want, but a bigger brain will consume more energy than a smaller brain, energy that
could be used for other activities like running away from predators.  Note that a big brain might not always be selected by evolution.  For one,
big brains require a lot of energy to run.  Our brains consume around 20% of our body's energy, despite being only about 2% of our body weight.
(Also, because of our big brains, childbirth has been especially treacherous for humans.  Thus, the width of women's hips has been a somewhat
literal bottleneck for our intelligence.)

Once the rabbits are dropped in Australia, the players won't be allowed to change the rabbits' design.  The players' rabbits should be adaptable
because Australia has a diverse environment, and no rabbit design will be optimal for all environments.  Because of the rabbits' computational
limitations, there will be rabbits that are "buggy" or suboptimal.  For example, from a computational-perception point of view, telling the
front end of a rabbit from the back is non-trivial, and we might end up having rabbits trying to mate with other rabbits by mounting the wrong
end.  (I've seen this happen, the rabbits were so eager to mate, they didn't seem to pay attention to the gender of the other rabbit, whether
the other rabbit was a close relative, or whether they were even mounting the back end of the other rabbit.)  But this is OK from an
evolutionary standpoint, because the extra computation might not be worth the brain matter needed to do it, and these bunnies will be at the
correct end half the time, which is good enough to reproduce.

***

To answer questions such as "What makes me happy?" or "Why does *x* make me happy?", we can gain some insight by stepping outside the humanities
and going down to biology, economics, and cognitive science.  A lot of what makes people happy can be explained in terms of these fields: e.g.,
men might enjoy sex with lots of different women because the type of people who did so had more kids and are more likely to be around.

I'm sure there are plenty of rabbits who mate like bunnies "because it feels good", and that rabbits have almost no concept of paternity.
Despite the short gestation period, they probably don't even realize that sex causes babies.

We can design our rabbits and talk about optimality from *the game's* point of view without looking at the rabbits' point of view at all.
Looking at the rabbits' point of view might lend insight onto the meaning of life: The rabbit's goal in life isn't necessarily *our* goal in the
game.  Imagine if I had a rational rabbit.  I'd tell my rabbit "Be fruitful and multiply!  That's why I created you.".  To which the rational
rabbit might respond, "No way!  I (actually, the routines that *you* wrote) want to go mate with hedgehogs!".  One other thing to note, this
rabbit's defiance (which causes its very desire for freedom and "free will") was programmed by me too because it was successful evolutionarily.

***

There are important differences in the process we'd use to design our rabbits and the process of evolution.  For example, evolution lacks
foresight.  For example, in male mammals, the vas deferens loops around the bladder, when a direct line would probably have been slightly more
advantageous.  As mammals became warm-blooded and their testes descended, the vas deferens had to follow the testes, resulting in the current
design.  Evolution is also slow and has "inertia", for example the myriad of evolutionary relics such as the hip bones of snakes.

Despite these differences, evolution often arrives at what might be called optimal solutions to problems.  For example, the process of evolution
arrived at the lens of our eyes, and, independently, the lens of the eyes of octopuses, which both have the same basic parabolic shape of lenses
that people have designed for cameras and other optics.  Therefore, some insights can be gained by considering what designs are successful even
if we ignore the design process itself.

There's also the principle of [The Selfish Gene](https://en.wikipedia.org/wiki/The_Selfish_Gene): our goal isn't really to make our rabbits take
over the island, but to make our rabbits' *genes* take over the island.  Thus, we'd want to design our rabbits such that their behaviour
sometimes might be bad for the reproductive success of an individual, but good for the individual's genes.  A classic example would be where a
rabbit sacrifices itself to a predator in order to save its offspring.

The reason that the goal of our game is to take over the island is that, in evolution, those beings that had a design that caused them to
reproduce were the ones that did reproduce.  So any animals living today (including humans) are here because their "designs" are likely to cause
them to reproduce (at least in the environment where they evolved).

An important point here is that, in general, *every* part of our innate being, both physically and mentally, is "designed" as it is because that
design traditionally helped our ancestors reproduce.

<!-- Likewise, *every* aspect of a plant is that way for a reason.  The reason is evolution.  Even -->
<!-- the designs of the flowers, and the shape of the leaves have been constrained to be the way -->
<!-- they are by some ruthless evolutionary process.  For example, the designs on some flowers -->
<!-- radiate inward, which acts, in effect, as guidance for insects coming, which come to pollinate -->
<!-- the flowers in exchange for a bit of nectar. -->

# Essay: Walking = Falling + Catching
#### 2020/09/20/10:04

TL;DR: Permanent happiness can never be achieved, or at least that it'd be a bad from a designer's point of view.  This section goes more
into some mechanisms a designer might want to put into an organism.  This is then used to explain why we can never have enough *Closet Space*.

***


> If I ever say to the moment: <br>
> Stay! You are so beautiful! <br>
> Then you may throw me into chains, <br>
> and I'll happily go to the abyss! <br>
>     --Johann Wolfgang von Goethe (from Faust, 1808)


> How much money is enough?  Just a little bit more. <br>
> --John D. Rockefeller (1839-1937)

The player with the most successful rabbits probably won't have the happiest rabbits.  We'd want our rabbits to be constantly moving forward.
We'd want them to only have enough glimpses of happiness or contentment that they don't give up completely.  This is how it is with human
nature, and it's this way for a good evolutionary reason.

An analogy might be made to walking.  When roboticists first began to make robots that could walk, they focused on stability.  If a walking
robot froze in its tracks it would be stable in the sense that it wouldn't fall down.  Because of this stability, it could walk as slowly as you
wanted it to.  This is contrasted to the gallop of a horse.  When a horse runs, there are instances when all 4 hooves are in the air at the same
time.  Thus, a horse can't gallop in "slow motion" because it can't be suspended with all its feet in the air at the same time.  The normal
walking gait of people isn't stable either.  During each step, our center of mass moves to its highest point when it is in front of the foot
that's on the ground.  So, we begin to *fall* forward, but our other foot rushes forward to *catch* us.  We then raise our center of mass and
"reset" the system for the next step.  So walking is falling and catching (or "controlled falling"), and you're never in a permanent stable
state.

Likewise, one way of getting our rabbits to reproduce is to have them built such that they're always on the edge: that they always feel like if
they do just this next goal, they'll be happy.  When they do accomplish the next goal, they get some reward, but not permanent happiness.  We
don't want our rabbits ever to be content because content rabbits don't reproduce as much as those that are constantly striving.  So our rabbits
will never actually attain fulfillment.  To do so would mean that the rabbits stop striving for more and stop reproducing.  On the other hand,
the rabbits' reward structure should be such that they don't give up either, because that would mean an end of reproduction too.

If I were designing people to reproduce (or gain power or help their offspring to reproduce), I'd also structure their reward system such that
they're always trying to attain something.  Like a moving carrot, I might also make them believe that if they only achieve this or that goal,
they'll be happy.  When they finally catch the carrot, I'll give them momentary happiness, but I'd structure them such that this happiness would
fade after some time and they'd devise a new goal.

So, it's possible that we can only distract ourselves from the feeling that might be described as emptiness or disquiet, that the emptiness
can't be banished, only put off.  For example, in Anna Karenina, the character Levin is happiest when he's mowing hay with a scythe.  It's a
simple action, but he's making "progress" on something.

***

In some video games "cheat codes" or "god" mode (where your character is invincible) makes the game boring quickly.  Likewise, suppose you found
a genie who would grant as many wishes as you wanted.  The wishes couldn't be contradictory or too poorly specified.  For example, the wish for
"permanent happiness" wouldn't be granted on the grounds that it's too vague.  With this genie you could make it such that the world was at
peace, famine and disease were gone, you had eternal life, money was virtually meaningless, you had all the women you could imagine, and your
friends, family and power were limitless.  But, would you ever be happy?  Can you imagine a situation where you don't have any more wishes to
make?

I suspect that there'd never be a *permanent* situation where a person was satisfied.  I suspect that (via evolution) the human reward system is
structured such that permanent happiness is impossible.  For people (or any evolutionary being), it'd make more sense if happiness was the
*event* of going to a better situation[^1].

[^1]: Recognizing that permanent fulfillment of desire is impossible, Buddhism teaches that a person should seek to free themselves from desire.
    On the face of it, this is a self-contradiction: a desire to have no desire.  If the tendency to become Buddhist were inheritable, these
    tendencies would become weeded out of our rabbits.  That is, a rabbit that had no desire to eat would soon starve.

***

If we want to win at Hare Wars, we'd also want our rabbits to use up all of their resources.  We'd want them to be greedy and lazy.  Laziness
encourages efficiency.  There should be some drive for our rabbits to try to find more efficient ways of accomplishing things, or ways of
reducing their own effort.  Because if they can do something with half the effort, they can do twice as much.

***

Why would we want our rabbits to exhaust their resources?  Consider what happens if a single pair of mice get into a stocked granary and go
unchecked.  They'll reproduce until there are thousands and thousands of mice and all the grain is gone... at which point almost all of the mice
will starve to death.  But any mouse with a long view who exercised some constraint in converting the grain into more mice would soon find
himself outnumbered by mice who don't have this constraint.  The *unconstrained* mouse would find himself *locally* successful.  By this, I mean
the mouse will outperform (i.e., out-reproduce) any other single mouse that doesn't use all of its resources.  The problem is that a *group* of
mice that exercises some constraint in managing their resources can do better in the long run than a group of short-sited mice.

There's almost always some bottleneck resource in nature though.  Nature is an arms race, in a sense.  For example, plants develop mechanisms,
such as poisons, to prevent themselves from being eaten by animals, and animals develop means (such as enzymes) to get around those mechanisms.
Usually, each party is just barely in front or behind the other, and this prevents either from completely dominating the other, unlike the mice
in the granary.

For most of our evolution, it was a rare thing to have a virtually unlimited supply of fatty foods.  Thus, because there was an *external*
constraint on the amount of bacon we could eat (i.e., its limited supply) there was no need to have an internal mechanism that limited our
intake of bacon.

# Essay: Squiggly Lines
#### 2020/10/28/11:15

There are tasks, such as understanding visual scenes, that we do so often that we don't realize how difficult they are... Until we try to solve
them in robots and other artificial systems.  So perception is non-trivial, and this means that a designer's goal doesn't always
agree with the organism's "meaning of life".

![]({{site.url}}/assets/beeeye.jpg "The Bumblebee's eye"){:width="600"}

***

Like gravity, our perception is so omnipresent that we hardly notice it.  So, it's easy to assume that perception takes little effort.  It's not
until working with a robot's perceptual system or image processing that one develops an idea of how difficult perception is.  The task of simply
identifying the objects in an image can be tricky (and despite "super human" performance on some benchmarks, computer vision is
still unsolved for more involved tasks like complex scene understanding).  This is because, fundamentally, perception is a problem of "Squiggly
Lines".

To illustrate what's meant by a problem of "squiggly lines", suppose we wanted to create a robotic bumblebee.  Also suppose that we were given
the bee's body and we just had to program its "brain".  The bee's compound eye is really just a set of light-sensors (called *ommatidia*).
Basically, each "surface" (or ommatidium) reports a value proportional to how much light is striking it (and different surfaces might be
sensitive to different colors or angles).  Unless we explicitly "tell" it, our robotic bee doesn't know what its sensors mean.  It just has the
sensor readings over time, which look like a bunch of *squiggly lines* if you plot them out.  That is, each of the bee's several thousand
receptors reports a signal, which can be plotted over time.  So, the bee's brain's input can be viewed as several thousand aligned plots.

![]({{site.url}}/assets/squigglyLines2.png "Squiggly lines, representing roughly 2% of what a bee sees over several seconds"){:width="600"}

Suppose I gave you plots of these sensors' readings, but I didn't tell you which sensor was which.  Suppose I didn't even tell you that these
are light sensors from a robotic bumblebee's eye.  As far as you would know, these could even be readings from a simulation of a mobile robot in
a 5 Dimensional world.  From this perspective, it's difficult to tell the difference between the squiggles produced by a flower and the
squiggles produced by a female bumblebee.  The bumblebee's perceptual system has two limiting factors: That of the distinguishing ability of the
bee's compound eye.  If a bee's vision is hopelessly blurry, then no amount of processing will be able to distinguish a flower from a female
bee.  The second limiting factor is that, even if the bee's vision is high resolution and crystal clear, a significant amount of computation is
needed to tell the difference between a flower and a female bee.  Although it'd look silly, we could give the bumblebee human eyes, but there
would still be the problem of processing all that data.  The bee's tiny brain couldn't do it.  It's worth noting that our own visual processing
system, the visual cortex, is many times the mass of a bee.  The human visual cortex has around 140 million neurons per hemisphere, while a
bee's entire brain is about one million neurons.

![]({{site.url}}/assets/bumblebee.jpeg "The Bumblebee Orchid"){:width="600"}

The [Bumblebee Orchid](https://en.wikipedia.org/wiki/Ophrys_bombyliflora) takes advantage of the limited perceptual systems of male bumblebees.
Its flowers "look" and smell like fertile female bumblebees.  That is, the flowers have the rough shape and coloring of female bumblebees, but
other than that, they don't actually look very much like female bumblebees.  (I can't say how similar they *smell* like them.)  With a glance, a
person can easily tell the difference between a bumblebee and a bumblebee orchid (though I have trouble telling males from females because of
*my* limited olfactory perceptual system).  However, they're good enough to trick the "low resolution" compound eyes and tiny brains of the
randy males, and the male bumblebees attempt to copulate with the flower, picking up and dropping off the flower's pollen so that *the flower*
can mate successfully.

***

![]({{site.url}}/assets/buckeyebutterfly.jpg "A Buckeye Butterfly, showing eye spots"){:width="600"}

The perceptual system and brain of a peacock (or a peahen, the female version) are much more sophisticated than that of a male bumblebee, but
these systems are still limited (as are ours!).  Bird's perceptual systems are particularly good at finding eyes.  A number of butterflies and
moths such as the Common Buckeye Butterfly, and the Promethea Silkmoth take advantage of this by having eyespots (because eyes are a giveaway
that something is animate).  These spots look a lot more like owls' eyes than the bumblebee orchids looks like bumblebees, but a person can
still easily tell the difference between one of these moths and an owl.  (Birds might actually be able to tell the difference if they look hard,
but they might not stick around long enough to do that.  Just in case.)  So, I assume that, like other birds and even some insects, peahen's
brains are good at recognizing eyespots.  That is, eyespots have a special place in the perceptual system of peahens.  So I'm guessing that
eyespots are so prevalent on peacock tails partially because of their special place in the perceptual systems of peahens.

<!-- Another (not incompatible) reason is that eyespots were originally useful for the peafowl (as -->
<!-- they are for the Buckeye Butterflies), and the genes got "recycled".  (The former reason at -->
<!-- least seems plausible to me.) -->


# Essay: Heuristics
#### 2020/11/11/10:55

If we're tasked to design the minds of our rabbits for maximal reproductive output, we're subject to computational and cognitive constraints.
Therefore, we need to make use of rules of thumb, or *heuristics*.
* Why do we like the things we like?  This falls out of a combination of "innate" heuristics and learning, mostly classical conditioning.
* Tastes can be heuristics for our ultimate goal, reproduction.  And tastes or heuristics can be developed for goals based on lower-level
  heuristics, so tastes can become "ungrounded" and arbitrarily complex.

***

Until he retired, my uncle worked as an engineer at Ford in Detroit.  He had bought one of their new models (a 1997 Taurus), and said that
although Ford's model was more aerodynamic, Chevrolet's competing model had higher sales because people "didn't like the way the Ford model
*looked*".  And the next model (the 2000 Taurus) ended up being redesigned with a more traditional --and less aerodynamic-- shape.

![]({{site.url}}/assets/buckeyebutterfly.jpg "A Buckeye Butterfly, showing eye spots"){:width="600"}


Why wouldn't people prefer the more aerodynamic model?  Isn't the goal to have the most "functional" car?  If not, what else might
people be trying to optimize?

One thing to note is that no one has a perfect wind tunnel simulator in their head.  Instead, people have to rely on heuristics or *tastes*.
There's a way that people develop their tastes in cars.  People see both the designs and the performance of fish, jet fighters, and cars.  After
many such examples, people develop an intuition for the kinds of features, such as sleekness, that make for a high performance
thing-traveling-through-medium.  People then associate these features with their performance.  So, without ever having taken a course on
aerodynamics, people can eyeball a car's body design and tell you (with better than random accuracy) whether it will outperform some other body
design.  This is in contrast to the more *analytical* conceptual system of car design which is what the designers at Ford use when they apply
equations and principles of aerodynamics to come up with a more exact answer for how aerodynamic the car is.  In reality, most systems in our
heads (and in the heads of the designers at Ford) are both intuitive and analytical.

This is the basic principle of how tastes are developed in general.  Like peahens, our perceptual abilities are limited (where we can't tell a
car's drag coefficient just by looking at it).  So, we have to develop associations of features to "value" (speed or performance in the case of
cars) so that we have an intuition to give us some idea of the value.

***

In stock market analysis, one can take a *technical* approach or a *fundamental* approach.  A purely technical analysis of a company's stock
looks only at the "trends" in the stock's selling price.  Books are written about how to "predict" what a stock will do given *only the history
of the stock's price*.  Generally, if a technical investor predicts that the stock's price will raise, he'll buy, and sell if the technical
analysis predicts the stock will drop.  In its most extreme form, a technical analysis wouldn't even look at what the company *does*.  A
fundamental analysis is at the opposite extreme: it will ignore the history of the stock's price, then make a prediction of the company's
earnings (and dividends) based on factors such as what capital the company owns, the "quality" of the people working for the company, and
whether the current economic situation means that people will want to buy the company's goods.  You can then assign the stock a fundamental
value based on the expected dividends and interest and inflation rates.  (For example, if you expect a share of Bifislurf Inc. to yield $5 in
dividends over the next year, and the inflation-adjusted interest rate is 5% per year, then a share of Bifislurf Inc. would have a fundamental
value of about $100, because that's how much money you'd need to put in the bank to get $5 of interest in a year.)  Generally, a pure
fundamental trader will buy if the stock's current price is (significantly) less than its fundamental value and sell if its price is higher.  An
interesting thing is that if everyone invested solely on fundamentals, the plot of the Dow Jones Industrial Average would be much smoother,
practically flat because it'd only reflect "real" changes in the companies' values.  (Tulip Mania also would've never happened if the tulip
traders used only fundamental analysis.  Tulips have little intrinsic value.) In reality, most traders use results from both fundamental and
technical analyses.

--

Another example of fundamentals and technicals: Flugtag is a contest/event sponsored by the Red Bull company in which teams build non-motorized
flying contraptions and launch them (carrying one of their members who is the "pilot") off a 30 ft. high ramp into a pool of water.  The teams
are judged primarily by 2 criteria: 1. the distance flown before landing in the water, and 2. the "creativity" of the contraption's design.  If
it weren't for the 2nd rule (which I'll call the "technical" rule), Flugtag would be a much more boring event.  What would happen, I predict, is
what happens with a myriad of other "purely fundamental" pursuits.  Initially, there'd be a broad range of designs, but eventually one of the
designs (or its basic principles, at least) would emerge as the "optimum", and most entrants would be minor variations on this optimum.  Take
airplanes, for example.  After the Wright Brothers' success, there was a blossoming of all sorts of crazy designs.  Take the Langley Flyer, for
example.  It actually predated the Wright Brothers' Flyer by several years.  Its full scale model was never fully capable of sustained flight,
but the smaller models had some success.  The interesting thing is that it looks completely unlike any airplane I've ever seen.  By World War
II, the basic body of the airplane (with a single aerofoil wing) converged to what's still used by commercial jets.  A similar process happened
with locomotives, automobiles, and computers.  Thus, Red Bull's 2nd rule explicitly puts a limit on the kind of convergence that would otherwise
happen.

***

Suppose I want to evaluate a piece of clothing.  For instance, I have *fundamental* criteria such as how comfortable a shirt will be, whether
it'll keep me warm on chilly days, and how difficult it'll be to wash it.  I also might be concerned with how I'll *look* in it, and I won't be
looking at myself much.  So I'm really concerned with associations other people will make of me when I'm wearing the shirt.

Now, there's one more factor of taste: associations made of people based on their appearance.  One can take a Holmesian approach and use logical
reasoning to deduce things about a person from their appearance, but we don't have enough time/brainpower to do this with every person we meet,
so we have to rely on our intuitions (or associations developed through experiences), just as we might in determining how "functional" a car
will be just from eyeballing it.

Some associations are formed from fundamentals.  If I see a picture of a person wearing a heavy coat and hat, I'll "guess" that the person's
somewhere cold.  This is because a heavy coat keeps you warm regardless of the coat's social context.  If a person's wearing glasses, they
probably don't have perfect vision without them.  Fundamentals are pretty easy, at least compared to technicals.  These don't have to do so much
with the intrinsic properties of things, but more with what the thing means for other people.  With clothes, technicals would be
"ornamentation", such as printed designs, the particulars of the cut of the fabric, and "flair".

I'd guess fashion designers spend 99% of their thought on technicals.  Ornamentation has its own abstract (and often intuitive) "rule system" as
well.  Like the peacock, you can't stray too far from the status quo.  The "fundamental" problems of clothing are pretty straightforward.  Like
the stock market, if clothes were designed only by fundamentals, fashions would hardly change at all.  (Changes would only be with innovations
such as with materials and manufacturing techniques, and with changes in what people use the clothes for.  For example, a much lower percentage
of Americans farm than was the case a century ago, so the average American doesn't need clothes designed for farm work.)

So, how do technicals and intuitions formed about technicals work to influence fashions?  Take bell bottom pants, for example.  The theory is
that attractive people originally started wearing bell bottoms.  (The reason for doing so may have been to distinguish themselves from "the
masses", or perhaps for the same reason very fit gazelles will flaunt their fitness in the face of approaching lions as if to say "Don't waste
your time chasing me, look how fit I am.".)  Then people began to associate bell bottoms with being attractive.  Then, (knowing about this
association (or having the association themselves), and maybe it's not explicit) less attractive people began wearing the bell bottoms so the
association would be transferred to *them*.  Eventually, so many unattractive people started wearing them, that *after a lag*, the association
became extinguished, and there was little reason to wear bell bottoms.

--

The book Freakonomics talks about similar trends with babies' names: people of high socio-economic status start naming their kids with a
particular group of names.  Then, the trend catches on because other people see that "The Beautiful People" are called by these names.  Thus,
people (from lower classes) form the association from the name (a nearly arbitrary symbol, practically) to the person's status, and name their
own kids with that name.  Eventually, the name becomes "common", the association is extinguished, and the upper classes find new names.

***

This association from technicals to fundamentals might be why people have certain tastes in food.  Oncologists have long known that you can
cause people to develop a strong aversion for almost any kind of food simply by putting their chemotherapy medicine in it a number of times.  My
theory is that you can similarly cause people to like just about any flavor by creating a fatty food with that flavor: I remember the first time
I had the Greek candy *halvah*.  My friend, Charles's mom, Zabia (who's father was Greek), offered it to me.  Despite its taste, which I
would've described as awkward but not *bad*, I ate it out of curiosity and politeness.  I had halvah several times after that, and soon
developed a taste for it.  Once, I found some commercially packaged halvah, and I read the label: halvah's made from crushed sesame seeds, and
is about 20% fat and 60% sugars by weight.  My theory is that fundamental "yumminess" is mostly fat and sugar, and that eventually we (or our
taste buds and the associated brain areas, to be precise) associate the flavor with the fat and sugar content.

***

I'd hazard to guess that virtually anyone can be conditioned to like almost anything.  (Well, anything that a large group of people also enjoy.
There are probably few people who could be conditioned to enjoy having their toenails removed.)  Through conditioning, almost anyone could
probably be made to enjoy the flavor of chocolate and dislike the flavor of vanilla, or vice versa.  Similarly, barring physical disability,
associations and reinforcement could be used to cause almost anyone to be made to enjoy mountain climbing, painting, or knitting.  To do this,
we'd just need to cause the association of the features of these activities with more fundamental rewards.

This raises the question of what the *fundamental* rewards for people are?  For our rabbits, they should be those that, when coupled with the
rabbits' cognitive systems, causes them to survive and reproduce.  Some rewards might be innate even though they could be learned from more
fundamental rewards.  For example, it might make sense to install in our rabbits an innate desire to not fall from high places (as a form of
bootstrapping), even though this desire is a "corollary" of the more fundamental desire to not break bones.  So, some of our rabbits' desires
could be redundant or even contradictory.
